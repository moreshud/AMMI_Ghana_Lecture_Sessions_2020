{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Practical Session DQN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opZzyYN7fwxD",
        "colab_type": "text"
      },
      "source": [
        "## Colab setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbV50a2jfwxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA_0eutEfwxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqhcwbE3fwxX",
        "colab_type": "code",
        "outputId": "9bbde006-229d-42bc-ce01-5e86421349e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (45.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFQNOxGsfwxc",
        "colab_type": "text"
      },
      "source": [
        "# Deep Q-Learning (DQN)\n",
        "\n",
        "\n",
        "In DQN, the $Q$-function is parameterized by a neural network of parameters $\\theta$. The network takes as input a state $s$ and outputs $Q(s, a, \\theta)$ for all actions $a$. \n",
        "\n",
        "The network is trained in way that is similar to Fitted Q Iteration. At each time $T$, the agent has observed the transitions $(s_t, a_t, r_t, s_t')_{t=1}^T$, which are stored in a __replay buffer__.\n",
        "\n",
        "In addition to the network with parameters $\\theta$, DQN keeps another network with the same architecture and parameters $\\tilde{\\theta}$, called __target network__. \n",
        "To update the parameters $\\theta$, we sample $N$ transitions from the __replay buffer__, we define the loss \n",
        "\n",
        "$$\n",
        "L(\\theta) = \\sum_{i=1}^N [Q(s_i, a_i, \\theta) - (r_i + \\gamma\\max_{a'}Q(s'_i,a', \\tilde{\\theta}))]^2\n",
        "$$\n",
        "\n",
        "and update \n",
        "\n",
        "$$\n",
        "\\theta \\gets \\theta + \\eta \\nabla L(\\theta).\n",
        "$$\n",
        "\n",
        "\n",
        "Every $C$ iterations, the target network is updated as $\\tilde{\\theta} \\gets \\theta$. \n",
        "\n",
        "At each time $t$, DQN updates the networks as described above, selects an action according to an $\\epsilon$-greedy policy, plays the action and stores the new data in the replay buffer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrBtkvHqfwxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from copy import deepcopy\n",
        "\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path\n",
        "\n",
        "import random, os.path, math, glob, csv, base64, itertools, sys\n",
        "from pprint import pprint\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import io\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz3beIAHfwxi",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Define the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV7lKaVGfwxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Environment\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "# Discount factor\n",
        "GAMMA = 0.99\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 256\n",
        "# Capacity of the replay buffer\n",
        "BUFFER_CAPACITY = 10000\n",
        "# Update target net every ... episodes\n",
        "UPDATE_TARGET_EVERY = 20\n",
        "\n",
        "# Initial value of epsilon\n",
        "EPSILON_START = 1.0\n",
        "# Parameter to decrease epsilon\n",
        "DECREASE_EPSILON = 200\n",
        "# Minimum value of epislon\n",
        "EPSILON_MIN = 0.05\n",
        "\n",
        "# Number of training episodes\n",
        "N_EPISODES = 200\n",
        "\n",
        "# Learning rate\n",
        "LEARNING_RATE = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4fVXZSafwxo",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Define the replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH1tb1wIfwxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, state, action, reward, next_state):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = (state, action, reward, next_state)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFgVBS8Gfwxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create instance of replay buffer\n",
        "replay_buffer = ReplayBuffer(BUFFER_CAPACITY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6ki1HpXfwxw",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Define the neural network architecture, objective and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP2R3fZ8fwxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic neural net.\n",
        "    \"\"\"\n",
        "    def __init__(self, obs_size, hidden_size, n_actions):\n",
        "        super(Net, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(obs_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Oz9uvzfwx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create network and target network\n",
        "hidden_size = 64\n",
        "obs_size = env.observation_space.shape[0]\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "q_net = Net(obs_size, hidden_size, n_actions)\n",
        "target_net = Net(obs_size, hidden_size, n_actions)\n",
        "\n",
        "# objective and optimizer\n",
        "objective = nn.MSELoss()\n",
        "optimizer = optim.Adam(params=q_net.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYeNGkE0fwx5",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Implement DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQqeJNoOfwx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "#  Some useful functions\n",
        "#\n",
        "\n",
        "def get_q(states):\n",
        "    \"\"\"\n",
        "    Compute Q function for a list of states\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        states_v = torch.FloatTensor([states])\n",
        "        output = q_net.forward(states_v).data.numpy()  # shape (1, len(states), n_actions)\n",
        "    return output[0, :, :]  # shape (len(states), n_actions)\n",
        "\n",
        "def eval_dqn(n_sim=5):\n",
        "    \"\"\"\n",
        "    Monte Carlo evaluation of DQN agent\n",
        "    \"\"\"\n",
        "    rewards = np.zeros(n_sim)\n",
        "    copy_env = deepcopy(env) # Important!\n",
        "    # Loop over number of simulations\n",
        "    for sim in range(n_sim):\n",
        "      state = copy_env.reset()\n",
        "      done = False\n",
        "      while not done:\n",
        "        action = choose_action(state, 0)\n",
        "        next_state, reward, done, _ = copy_env.step(action)\n",
        "        # update sum of rewards\n",
        "        rewards[sim] += reward\n",
        "        state = next_state\n",
        "    return rewards"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvgkbH0Vfwx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_action(state, epsilon):\n",
        "    \"\"\"\n",
        "    TO BE IMPLEMENTED\n",
        "    \n",
        "    Return action according to an epsilon-greedy exploration policy\n",
        "    \"\"\"\n",
        "    q_state = get_q([state])[0] # array of shape (n_actions,)\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "      action = env.action_space.sample() # random action\n",
        "    else:\n",
        "      action = q_state.argmax()\n",
        "    return action\n",
        "    \n",
        "\n",
        "def update(state, action, reward, next_state, done):\n",
        "    \"\"\"\n",
        "    TO BE COMPLETED\n",
        "    \"\"\"\n",
        "    \n",
        "    # add data to replay buffer\n",
        "    if done:\n",
        "        next_state = None\n",
        "    replay_buffer.push(state, action, reward, next_state)\n",
        "    \n",
        "    if len(replay_buffer) < BATCH_SIZE:\n",
        "        return np.inf\n",
        "    \n",
        "    # get batch\n",
        "    # transitions = list of (state, action, reward, next_state)\n",
        "    transitions = replay_buffer.sample(BATCH_SIZE)\n",
        "\n",
        "    # 1st thing: compute Q(s_i, a_i, theta) for all (s_i, a_i)\n",
        "    # in the batch\n",
        "    \n",
        "    # Build tensor with s_i and tensor with a_i\n",
        "    batch_states = torch.FloatTensor( \n",
        "                    [ transitions[ii][0] for ii in range(BATCH_SIZE) ]\n",
        "                    )\n",
        "    batch_actions = torch.LongTensor(  # type is important (Long) \n",
        "                    [ transitions[ii][1] for ii in range(BATCH_SIZE) ]\n",
        "                    )\n",
        "    batch_rewards = torch.FloatTensor( \n",
        "                    [ transitions[ii][2] for ii in range(BATCH_SIZE) ]\n",
        "                    )\n",
        "\n",
        "    non_final_mask = torch.tensor([(transitions[ii][3] is not None) \n",
        "                                   for ii in range(BATCH_SIZE)], dtype=torch.bool)\n",
        "    non_final_next_states = torch.FloatTensor(\n",
        "            [transitions[ii][3]  for ii in range(BATCH_SIZE) \n",
        "            if transitions[ii][3] is not None])\n",
        "        \n",
        "    next_state_values = torch.zeros(BATCH_SIZE)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    state_action_values = q_net(batch_states).gather(1, batch_actions.view(-1, 1))\n",
        "\n",
        "    # Compute loss - TO BE IMPLEMENTED!\n",
        "    values  = state_action_values\n",
        "    targets = batch_rewards + GAMMA*next_state_values\n",
        "    loss = objective(values, targets.unsqueeze(1))\n",
        "     \n",
        "    # Optimize the model - UNCOMMENT!\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUzuCwdcfwyC",
        "colab_type": "code",
        "outputId": "41f521c0-2860-46f3-ba5f-6d6569ecdda4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "#\n",
        "# Train\n",
        "# \n",
        "\n",
        "EVAL_EVERY = 5\n",
        "REWARD_THRESHOLD = 199\n",
        "\n",
        "def train():\n",
        "    state = env.reset()\n",
        "    epsilon = EPSILON_START\n",
        "    ep = 0\n",
        "    total_time = 0\n",
        "    while ep < N_EPISODES:\n",
        "        action = choose_action(state, epsilon) # eps-greedy \n",
        "\n",
        "        # take action and update replay buffer and networks\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        loss = update(state, action, reward, next_state, done)\n",
        "\n",
        "        # update state\n",
        "        state = next_state\n",
        "\n",
        "        # end episode if done\n",
        "        if done:\n",
        "            state = env.reset()\n",
        "            ep   += 1\n",
        "            if ( (ep+1)% EVAL_EVERY == 0):\n",
        "                rewards = eval_dqn()\n",
        "                print(\"episode =\", ep+1, \", reward = \", np.mean(rewards),\n",
        "                      \"loss = \", loss)\n",
        "                if np.mean(rewards) >= REWARD_THRESHOLD:\n",
        "                    break\n",
        "\n",
        "            # update target network\n",
        "            if ep % UPDATE_TARGET_EVERY == 0:\n",
        "                target_net.load_state_dict(q_net.state_dict())\n",
        "            # decrease epsilon\n",
        "            epsilon = EPSILON_MIN + (EPSILON_START - EPSILON_MIN) * \\\n",
        "                            np.exp(-1. * ep / DECREASE_EPSILON )    \n",
        "\n",
        "        total_time += 1\n",
        "\n",
        "train()\n",
        "rewards = eval_dqn(20)\n",
        "print(\"\")\n",
        "print(\"mean reward after training = \", np.mean(rewards))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode = 5 , reward =  9.6 loss =  inf\n",
            "episode = 10 , reward =  9.2 loss =  inf\n",
            "episode = 15 , reward =  10.8 loss =  0.0010640535\n",
            "episode = 20 , reward =  10.6 loss =  0.00084935164\n",
            "episode = 25 , reward =  10.8 loss =  0.031724412\n",
            "episode = 30 , reward =  9.2 loss =  0.024328005\n",
            "episode = 35 , reward =  9.8 loss =  0.012972575\n",
            "episode = 40 , reward =  9.8 loss =  0.016440364\n",
            "episode = 45 , reward =  12.8 loss =  0.03297592\n",
            "episode = 50 , reward =  11.4 loss =  0.017718593\n",
            "episode = 55 , reward =  61.2 loss =  0.01807854\n",
            "episode = 60 , reward =  10.4 loss =  0.0176648\n",
            "episode = 65 , reward =  9.4 loss =  0.028467113\n",
            "episode = 70 , reward =  9.4 loss =  0.019334458\n",
            "episode = 75 , reward =  20.4 loss =  0.039791133\n",
            "episode = 80 , reward =  9.4 loss =  0.020291964\n",
            "episode = 85 , reward =  91.0 loss =  0.057677507\n",
            "episode = 90 , reward =  9.6 loss =  0.037236962\n",
            "episode = 95 , reward =  23.0 loss =  0.037255805\n",
            "episode = 100 , reward =  25.0 loss =  0.07538158\n",
            "episode = 105 , reward =  43.4 loss =  0.08471128\n",
            "episode = 110 , reward =  63.2 loss =  0.051281787\n",
            "episode = 115 , reward =  42.8 loss =  0.11261339\n",
            "episode = 120 , reward =  9.8 loss =  0.07260944\n",
            "episode = 125 , reward =  42.6 loss =  0.12177128\n",
            "episode = 130 , reward =  46.6 loss =  0.16525786\n",
            "episode = 135 , reward =  28.4 loss =  0.055750873\n",
            "episode = 140 , reward =  54.4 loss =  0.13040197\n",
            "episode = 145 , reward =  86.6 loss =  0.1685276\n",
            "episode = 150 , reward =  90.0 loss =  0.3842181\n",
            "episode = 155 , reward =  101.8 loss =  0.26038343\n",
            "episode = 160 , reward =  88.4 loss =  0.13370997\n",
            "episode = 165 , reward =  99.4 loss =  0.53029424\n",
            "episode = 170 , reward =  103.6 loss =  0.209344\n",
            "episode = 175 , reward =  112.2 loss =  0.13775656\n",
            "episode = 180 , reward =  107.4 loss =  0.25168028\n",
            "episode = 185 , reward =  108.6 loss =  0.6742261\n",
            "episode = 190 , reward =  100.4 loss =  0.27195144\n",
            "episode = 195 , reward =  105.2 loss =  0.41567305\n",
            "episode = 200 , reward =  100.4 loss =  0.72107667\n",
            "\n",
            "mean reward after training =  98.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhWv6ThkfwyG",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing the agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0sGUpzJfwyH",
        "colab_type": "code",
        "outputId": "30ff585e-2209-4d42-bce5-88da9883ad1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "def show_video(directory):\n",
        "    html = []\n",
        "    for mp4 in Path(directory).glob(\"*.mp4\"):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append('''<video alt=\"{}\" autoplay \n",
        "                      loop controls style=\"height: 400px;\">\n",
        "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
        "    \n",
        "def make_seed(seed):\n",
        "    np.random.seed(seed=seed)\n",
        "    torch.manual_seed(seed=seed)\n",
        "  \n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Fhe2iefwyM",
        "colab_type": "code",
        "outputId": "36a6d946-fd34-4ec9-b52b-6a9ee639a62b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "env = Monitor(env, \"./gym-results\", force=True, video_callable=lambda episode: True)\n",
        "for episode in range(1):\n",
        "    done = False\n",
        "    state = env.reset()\n",
        "    while not done:\n",
        "        action = choose_action(state, 0) # MODIFY THIS PART TO COMPUTE THE ACTION WITH DQN\n",
        "        state, reward, done, info = env.step(action)\n",
        "env.close()\n",
        "show_video(\"./gym-results\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"gym-results/openaigym.video.0.117.video000000.mp4\" autoplay \n",
              "                      loop controls style=\"height: 400px;\">\n",
              "                      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                 </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}