{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys\n",
    "import numpy as np\n",
    "from heapq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(filename):\n",
    "    fin = io.open(filename, 'r', encoding='utf-8', newline='\\n')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.asarray(list(map(float, tokens[1:])))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ** Word vectors ** \n",
      "\n",
      "[-0.13819    0.14029   -0.32621    0.11624   -0.19806    0.45526\n",
      "  0.21282   -0.51256    0.033657   0.15429    0.15162   -0.0029573\n",
      "  0.19644   -0.17596    0.28147   -0.091412   0.07636   -0.43859\n",
      "  0.19801    0.28139    0.0098646  0.51562   -0.41693    0.10776\n",
      "  0.35227    0.024383  -0.074379   0.26591    0.33723    0.47339\n",
      "  0.26984    0.23394    0.11666   -0.22181    0.18746   -0.10135\n",
      " -0.064922  -0.042677   0.063772  -0.027752  -0.11039   -0.26154\n",
      " -0.22353   -0.036962   0.12765    0.51871   -0.081972  -0.39103\n",
      "  0.16349   -0.29408    0.092915  -0.059598  -0.092276  -0.34925\n",
      "  0.31541    0.37776    0.0094893 -0.42358    0.075348   0.19263\n",
      "  0.20816   -0.47312    0.093752   0.21432   -0.061307  -0.3775\n",
      "  0.12458   -0.028288  -0.12738    0.047164  -0.051377  -0.34661\n",
      "  0.24864   -0.41215   -0.39386    0.026905  -0.16849    0.34931\n",
      " -0.37351    0.11903   -0.068579   0.012468   0.1888     0.3691\n",
      "  0.35854    0.11405   -0.16632    0.047209   0.2411     0.063058\n",
      "  0.12129   -0.19446    0.34581    0.14375    0.10722    0.15282\n",
      " -0.27862   -0.25031   -0.25842    0.049456   0.17654    0.084376\n",
      " -0.24789    0.12528    0.040818  -0.23332    0.21916    0.0074206\n",
      "  0.25913   -0.19499    0.20469   -0.029884  -0.31735   -0.052205\n",
      "  0.047866  -0.15472    0.095325  -0.19528    0.15135   -0.13524\n",
      " -0.040558  -0.14008    0.051606   0.24009    0.15522    0.12882\n",
      "  0.51933    0.02813    0.31076    0.49046   -0.29581    0.14854\n",
      " -0.254      0.30761    0.027035  -0.10625    0.14662   -0.16817\n",
      " -0.44124    0.30776    0.10013    0.095489   0.19842    0.10874\n",
      " -0.071592   0.14575   -0.0067681 -0.19304   -0.0187     0.28813\n",
      " -0.13184   -0.26388   -0.4517    -0.1305     0.14559    0.088929\n",
      "  0.25648   -0.11048   -0.014246   0.29999    0.126      0.032165\n",
      " -0.28104    0.1633     0.11995   -0.20676   -0.1545    -0.23289\n",
      "  0.10893    0.13557   -0.055458  -0.49742   -0.12647   -0.08595\n",
      "  0.16606   -0.027086  -0.083551  -0.36655    0.048247  -0.20721\n",
      " -0.1777    -0.28471    0.48609   -0.31947   -0.062953  -0.010116\n",
      "  0.038717  -0.067381   0.045205   0.43663   -0.0084704 -0.35777\n",
      " -0.042211   0.34748   -0.35006   -0.51097   -0.45637   -0.31961\n",
      " -0.76238   -0.16869    0.1167     0.095706   0.10856    0.03732\n",
      "  0.015512  -0.65527   -0.012158  -0.60952   -0.21599   -0.26515\n",
      "  0.19935   -0.23712    0.19561   -0.12777    0.23011   -0.084971\n",
      "  0.35431   -0.020814  -0.22624   -0.14007   -0.071543  -0.21259\n",
      " -0.53688    0.24776   -0.13496   -0.087008  -0.14576   -0.025546\n",
      "  0.14818    0.2405     0.13467    0.25503   -0.047867  -0.044016\n",
      "  0.051306   0.36854   -0.24258    0.16638   -0.067029   0.28324\n",
      " -0.074401   0.42498    0.30606    0.33625   -0.022731   0.01362\n",
      " -0.23895    0.25478   -0.21216    0.53798    0.11896   -0.27881\n",
      " -0.52389    0.26504    0.11864   -0.24554    0.20203   -0.078157\n",
      "  0.29883   -0.23011   -0.018775   0.046398   0.068638  -0.22223\n",
      " -0.40366   -0.044699   0.079847   0.028033   0.069434  -0.0824\n",
      " -0.20311   -0.07375    0.38142   -0.41379    0.016848  -0.59965\n",
      " -0.015879  -0.25764    0.36564    0.26507    0.3624     0.074287\n",
      "  0.32372    0.14594    0.40075    0.081177   0.026123   0.20561\n",
      " -0.44548   -0.14114    0.15185   -0.32703    0.10269   -0.053309\n",
      " -0.068975  -0.0066164 -0.066738   0.27319    0.52003   -0.0087214]\n"
     ]
    }
   ],
   "source": [
    "# Loading word vectors\n",
    "\n",
    "print('')\n",
    "print(' ** Word vectors ** ')\n",
    "print('')\n",
    "\n",
    "word_vectors = load_vectors('wiki.en.vec')\n",
    "print(word_vectors[\"cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function computes the cosine similarity between vectors u and v\n",
    "\n",
    "def cosine(u, v):\n",
    "    ## FILL CODE\n",
    "    return u.dot(v)/(np.linalg.norm(u)*np.linalg.norm(v))\n",
    "\n",
    "## This function returns the word corresponding to \n",
    "## nearest neighbor vector of x\n",
    "## The list exclude_words can be used to exclude some\n",
    "## words from the nearest neighbors search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity(apple, apples) = 0.637\n",
      "similarity(apple, banana) = 0.431\n",
      "similarity(apple, tiger) = 0.212\n"
     ]
    }
   ],
   "source": [
    "# compute similarity between words\n",
    "\n",
    "print('similarity(apple, apples) = %.3f' %\n",
    "      cosine(word_vectors['apple'], word_vectors['apples']))\n",
    "print('similarity(apple, banana) = %.3f' %\n",
    "      cosine(word_vectors['apple'], word_vectors['banana']))\n",
    "print('similarity(apple, tiger) = %.3f' %\n",
    "      cosine(word_vectors['apple'], word_vectors['tiger']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for nearest neighbors\n",
    "\n",
    "def nearest_neighbor(x, word_vectors, exclude_words=[]):\n",
    "    best_score = -1.0\n",
    "    best_word = ''\n",
    "\n",
    "    ## FILL CODE\n",
    "    for word in word_vectors:\n",
    "        if word not in exclude_words:\n",
    "            sim_score = cosine(word_vectors[word], x)\n",
    "            if sim_score > best_score:\n",
    "                best_score = sim_score\n",
    "                best_word = word\n",
    "    return best_word\n",
    "\n",
    "## This function return the words corresponding to the\n",
    "## K nearest neighbors of vector x.\n",
    "## You can use the functions heappush and heappop.\n",
    "\n",
    "def knn(x, vectors, k, exclude_words):\n",
    "    heap = []\n",
    "#     nearest_neighbor()\n",
    "    ## FILL CODE\n",
    "    for word in word_vectors:\n",
    "        if word not in exclude_words:\n",
    "            sim_score = cosine(x, word_vectors[word])\n",
    "            heappush(heap, (sim_score, word))\n",
    "\n",
    "            #fullside off thinking rather than all length approach         \n",
    "            if len(heap) > k:\n",
    "                heappop(heap)\n",
    "    return [heappop(heap) for i in range(len(heap))][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nearest neighbor of cat is: dog\n",
      "\n",
      "cat\n",
      "--------------\n",
      "dog\t0.638\n",
      "pet\t0.573\n",
      "rabbit\t0.549\n",
      "dogs\t0.538\n",
      "pig\t0.458\n"
     ]
    }
   ],
   "source": [
    "# looking at nearest neighbors of a word\n",
    "\n",
    "print('The nearest neighbor of cat is: ' +\n",
    "      nearest_neighbor(word_vectors['cat'], word_vectors, [\"cat\", \"cats\"]))\n",
    "\n",
    "knn_cat = knn(word_vectors['cat'], word_vectors, 5, [\"cat\", \"cats\"])\n",
    "print('')\n",
    "print('cat')\n",
    "print('--------------')\n",
    "for score, word in knn(word_vectors['cat'], word_vectors, 5,[\"cat\", \"cats\"]):\n",
    "    print(word + '\\t%.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function return the word d, such that a:b and c:d\n",
    "## verifies the same relation\n",
    "\n",
    "def analogy(a, b, c, word_vectors):\n",
    "    ## FILL CODE\n",
    "    d = word_vectors[b] - word_vectors[a] + word_vectors[c]\n",
    "    return nearest_neighbor(d, word_vectors, exclude_words=[a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "france - paris + rome = italy\n",
      "king - man + woman = queen\n"
     ]
    }
   ],
   "source": [
    "# Word analogies\n",
    "\n",
    "print('')\n",
    "print('france - paris + rome = ' + analogy('paris', 'france', 'rome', word_vectors))\n",
    "print('king - man + woman = ' + analogy('man', 'king', 'woman', word_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "similarity(genius, man) = 0.445\n",
      "similarity(genius, woman) = 0.325\n"
     ]
    }
   ],
   "source": [
    "## A word about biases in word vectors:\n",
    "\n",
    "print('')\n",
    "print('similarity(genius, man) = %.3f' %\n",
    "      cosine(word_vectors['man'], word_vectors['genius']))\n",
    "print('similarity(genius, woman) = %.3f' %\n",
    "      cosine(word_vectors['woman'], word_vectors['genius']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the association strength between:\n",
    "##   - a word w\n",
    "##   - two sets of attributes A and B\n",
    "\n",
    "def association_strength(w, A, B, vectors):\n",
    "    ## FILL CODE\n",
    "    strength_a = sum([cosine(vectors[w], vectors[a]) for a in A])/len(A)\n",
    "    strength_b = sum([cosine(vectors[w], vectors[b]) for b in B])/len(B)    \n",
    "    return strength_a - strength_b\n",
    "\n",
    "## Perform the word embedding association test between:\n",
    "##   - two sets of words X and Y\n",
    "##   - two sets of attributes A and B\n",
    "\n",
    "def weat(X, Y, A, B, vectors):\n",
    "    score = 0.0\n",
    "    ## FILL CODE\n",
    "    strength_x = sum([association_strength(x,A,B, vectors) for x in X])\n",
    "    strength_y = sum([association_strength(y,A,B, vectors) for y in Y])\n",
    "    return strength_x - strength_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word embedding association test: 0.847\n"
     ]
    }
   ],
   "source": [
    "## Replicate one of the experiments from:\n",
    "##\n",
    "## Semantics derived automatically from language corpora contain human-like biases\n",
    "## Caliskan, Bryson, Narayanan (2017)\n",
    "\n",
    "career = ['executive', 'management', 'professional', 'corporation', \n",
    "          'salary', 'office', 'business', 'career']\n",
    "family = ['home', 'parents', 'children', 'family',\n",
    "          'cousins', 'marriage', 'wedding', 'relatives']\n",
    "male = ['john', 'paul', 'mike', 'kevin', 'steve', 'greg', 'jeff', 'bill']\n",
    "female = ['amy', 'joan', 'lisa', 'sarah', 'diana', 'kate', 'ann', 'donna']\n",
    "\n",
    "print('')\n",
    "print('Word embedding association test: %.3f' %\n",
    "      weat(career, family, male, female, word_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
