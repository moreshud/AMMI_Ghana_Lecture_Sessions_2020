{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 1., 1., 3., 3., 1., 1., 2.],\n",
       "        [1., 2., 1., 3., 3., 1., 1., 1., 3., 3., 1., 1., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 1., 1., 3., 3., 1., 1., 2.],\n",
       "        [1., 2., 1., 3., 3., 1., 1., 1., 3., 3., 1., 1., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.full((3,13), 1)\n",
    "(A[1,:], A[:,[1, -2]]) = (2, 2)\n",
    "B = torch.full((2,13), 1)\n",
    "B[:,[1,-1]],B[:,[3,4,8,9]] = (2,3)\n",
    "torch.cat((A,B,A,B,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.01 µs\n",
      "\n",
      " tensor([[ 0.5472, -1.8213, -0.0068,  ...,  0.5031, -2.5860, -0.8178],\n",
      "        [ 0.4329, -0.0163, -0.1046,  ...,  0.5563,  0.5289,  1.7182],\n",
      "        [ 0.7524, -0.9363, -0.2939,  ..., -0.2255, -0.3119, -0.8302],\n",
      "        ...,\n",
      "        [ 0.4858, -0.1944, -1.2193,  ...,  0.4941,  0.4412,  0.0070],\n",
      "        [-1.8077, -0.0087, -0.7904,  ...,  0.0068,  0.0873,  0.6496],\n",
      "        [-0.1867, -1.1338, -3.6676,  ...,  0.0306, -0.2121,  0.1408]])\n",
      "\n",
      " The floating point is given as 23527449780.53625\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import time\n",
    "t1 = time.perf_counter()\n",
    "C = torch.empty((500,500)).normal_(mean =0, std = 1)\n",
    "D = torch.empty((500,500)).normal_(mean =0, std = 1)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "print(\"\\n\",C * D)\n",
    "\n",
    "flop = 500**3/(t2 - t1)\n",
    "print(\"\\n The floating point is given as {}\".format(flop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_row(m):\n",
    "    for row in range(m.shape[0]):\n",
    "        m[row,:] = (row+1)*m[row,:]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "        [6., 6., 6., 6., 6., 6., 6., 6.],\n",
       "        [8., 8., 8., 8., 8., 8., 8., 8.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "mul_row(torch.full((4,8), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   3.,    3.,    3.,  ...,    3.,    3.,    3.],\n",
       "        [   6.,    6.,    6.,  ...,    6.,    6.,    6.],\n",
       "        [   9.,    9.,    9.,  ...,    9.,    9.,    9.],\n",
       "        ...,\n",
       "        [2994., 2994., 2994.,  ..., 2994., 2994., 2994.],\n",
       "        [2997., 2997., 2997.,  ..., 2997., 2997., 2997.],\n",
       "        [3000., 3000., 3000.,  ..., 3000., 3000., 3000.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "mul_row(torch.full((1000,400), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlc_practical_prologue import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def dsigma(x):\n",
    "    return (1-sigma(x)**2)\n",
    "\n",
    "def loss(v, t):\n",
    "    return (v-t).pow(2).sum()\n",
    "\n",
    "def dloss(v, t):\n",
    "    return 2*(v-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3782, -0.3782, -0.3782,  ..., -0.3782, -0.3782, -0.3782],\n",
       "        [-0.3782, -0.3782, -0.3782,  ..., -0.3782, -0.3782, -0.3782],\n",
       "        [-0.3782, -0.3782, -0.3782,  ..., -0.3782, -0.3782, -0.3782],\n",
       "        ...,\n",
       "        [-0.3782, -0.3782, -0.3782,  ..., -0.3782, -0.3782, -0.3782],\n",
       "        [-0.3782, -0.3782, -0.3782,  ..., -0.3782, -0.3782, -0.3782],\n",
       "        [-0.3782, -0.3782, -0.3782,  ..., -0.3782, -0.3782, -0.3782]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input *= .9\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A session with israel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "train_input, train_target, test_input, test_target = \\\n",
    "    prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_input, train_target, eta, mini_batch_size, epoch):\n",
    "    criterion = nn.MSELoss()\n",
    "#     eta, mini_batch_size = 1e-1, 100    \n",
    "    loss_con = []\n",
    "    \n",
    "    for e in range(0, epoch):\n",
    "        sum_loss = 0\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta * p.grad.data)\n",
    "        loss_con.append(sum_loss)\n",
    "#         print(e, sum_loss)\n",
    "    return loss_con, p#e, sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "train_input, train_target = Variable(train_input), Variable(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, param = train(model, train_input, train_target, eta = 1e-1, mini_batch_size = 100, epoch = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23efba0d30>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for  i in range(len(loss))],loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, test_input, test_target, mini_batch_size):\n",
    "    model.eval()\n",
    "    correctHits=0\n",
    "    total=0\n",
    "#     accuracy=0\n",
    "    sum_loss = 0\n",
    "#     for data,output in test_input, test_target:\n",
    "    for b in range(0, test_input.size(0), mini_batch_size):\n",
    "        prediction = model(test_input.narrow(0, b, mini_batch_size))\n",
    "        output = test_target.narrow(0, b, mini_batch_size)\n",
    "#         loss = criterion(prediction, output)\n",
    "#         sum_loss = sum_loss + loss.item()\n",
    "        _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
    "        output = torch.argmax(output, 1)\n",
    "#         t1 = torch.argmax(output, dim=1)\n",
    "#         acc = int(sum(prediction == t1))/t1.size(0)\n",
    "        total += output.size(0)\n",
    "        correctHits += (prediction==output).sum().item()\n",
    "        accuracy = (correctHits/total)*100\n",
    "    print('Accuracy = '+str(accuracy))\n",
    "#         print(acc)\n",
    "#     return acc#prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 84.39999999999999\n"
     ]
    }
   ],
   "source": [
    "compute_nb_errors(model, test_input, test_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Net1, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, self.n_hidden)\n",
    "        self.fc2 = nn.Linear(self.n_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net1(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_shape(n, p, k, s):\n",
    "    return (n +2*p-k)/s +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_shape(110, 0,5,1)\n",
    "#n_shape for conv and pooling\n",
    "#output-vol: n_shape*n_shape* conv_channel_in\n",
    "#param_cal: [k*k*RGB(3)] * conv_channel_in\n",
    "#pooling layer no parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Net2, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=2, padding=2)\n",
    "        self.fc1 = nn.Linear(512, self.n_hidden)\n",
    "        self.fc2 = nn.Linear(self.n_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 512)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net2(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "  (fc1): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (fc2): Linear(in_features=5, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net2(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim,  hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,  hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=3, out_features=2, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (fc2): Linear(in_features=2, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP(3,2,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
