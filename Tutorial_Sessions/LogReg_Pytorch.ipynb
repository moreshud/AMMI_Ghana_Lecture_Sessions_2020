{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646a0bfca5c34b388e548233332de811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9a12aae4b243fb8c8dd5ba9ee2f555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16223ab92fdb4d94a9916e176821dab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063f999cd1f24e3abf45171725835758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw\n",
      "Processing...\n",
      "\n",
      "\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the Fashion MNIST data\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='../datasets', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='../datasets', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Logistic Regression Class\n",
    "\n",
    "class logsticRegression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(logsticRegression, self).__init__()\n",
    "        self.logstic = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.logstic(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logsticRegression(28 * 28, 10) \n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # try out different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "epoch 1\n",
      "[1/100] Loss: 2.018422, Acc: 0.423021\n",
      "[1/100] Loss: 1.838941, Acc: 0.526875\n",
      "[1/100] Loss: 1.704756, Acc: 0.572622\n",
      "Finish 1 epoch, Loss: 1.690278, Acc: 0.576459\n",
      "Test Loss: 1.349889, Acc: 0.657444\n",
      "Time:7.2 s\n",
      "**********\n",
      "epoch 2\n",
      "[2/100] Loss: 1.292466, Acc: 0.665260\n",
      "[2/100] Loss: 1.242395, Acc: 0.670599\n",
      "[2/100] Loss: 1.201422, Acc: 0.675104\n",
      "Finish 2 epoch, Loss: 1.195867, Acc: 0.675656\n",
      "Test Loss: 1.096453, Acc: 0.669785\n",
      "Time:6.1 s\n",
      "**********\n",
      "epoch 3\n",
      "[3/100] Loss: 1.061756, Acc: 0.685781\n",
      "[3/100] Loss: 1.042553, Acc: 0.691484\n",
      "[3/100] Loss: 1.023173, Acc: 0.693733\n",
      "Finish 3 epoch, Loss: 1.021310, Acc: 0.694280\n",
      "Test Loss: 0.978297, Acc: 0.690983\n",
      "Time:5.7 s\n",
      "**********\n",
      "epoch 4\n",
      "[4/100] Loss: 0.961560, Acc: 0.701146\n",
      "[4/100] Loss: 0.943415, Acc: 0.708724\n",
      "[4/100] Loss: 0.929906, Acc: 0.711580\n",
      "Finish 4 epoch, Loss: 0.929306, Acc: 0.711371\n",
      "Test Loss: 0.907984, Acc: 0.710788\n",
      "Time:7.0 s\n",
      "**********\n",
      "epoch 5\n",
      "[5/100] Loss: 0.878396, Acc: 0.727240\n",
      "[5/100] Loss: 0.874654, Acc: 0.727161\n",
      "[5/100] Loss: 0.870134, Acc: 0.729132\n",
      "Finish 5 epoch, Loss: 0.870203, Acc: 0.729078\n",
      "Test Loss: 0.859909, Acc: 0.724124\n",
      "Time:5.7 s\n",
      "**********\n",
      "epoch 6\n",
      "[6/100] Loss: 0.841220, Acc: 0.741719\n",
      "[6/100] Loss: 0.834406, Acc: 0.740547\n",
      "[6/100] Loss: 0.829320, Acc: 0.741944\n",
      "Finish 6 epoch, Loss: 0.827773, Acc: 0.742321\n",
      "Test Loss: 0.823857, Acc: 0.735967\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 7\n",
      "[7/100] Loss: 0.802437, Acc: 0.749948\n",
      "[7/100] Loss: 0.798030, Acc: 0.752656\n",
      "[7/100] Loss: 0.795570, Acc: 0.752569\n",
      "Finish 7 epoch, Loss: 0.795474, Acc: 0.752865\n",
      "Test Loss: 0.795871, Acc: 0.743033\n",
      "Time:5.8 s\n",
      "**********\n",
      "epoch 8\n",
      "[8/100] Loss: 0.771271, Acc: 0.759948\n",
      "[8/100] Loss: 0.771205, Acc: 0.759818\n",
      "[8/100] Loss: 0.769560, Acc: 0.760503\n",
      "Finish 8 epoch, Loss: 0.769440, Acc: 0.760195\n",
      "Test Loss: 0.773057, Acc: 0.751194\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 9\n",
      "[9/100] Loss: 0.754193, Acc: 0.766563\n",
      "[9/100] Loss: 0.751723, Acc: 0.766120\n",
      "[9/100] Loss: 0.748142, Acc: 0.766753\n",
      "Finish 9 epoch, Loss: 0.747947, Acc: 0.766691\n",
      "Test Loss: 0.753811, Acc: 0.755374\n",
      "Time:6.1 s\n",
      "**********\n",
      "epoch 10\n",
      "[10/100] Loss: 0.727926, Acc: 0.773698\n",
      "[10/100] Loss: 0.732839, Acc: 0.768828\n",
      "[10/100] Loss: 0.730584, Acc: 0.771233\n",
      "Finish 10 epoch, Loss: 0.729919, Acc: 0.771888\n",
      "Test Loss: 0.737452, Acc: 0.760450\n",
      "Time:6.4 s\n",
      "**********\n",
      "epoch 11\n",
      "[11/100] Loss: 0.714920, Acc: 0.778177\n",
      "[11/100] Loss: 0.713604, Acc: 0.777865\n",
      "[11/100] Loss: 0.714320, Acc: 0.776493\n",
      "Finish 11 epoch, Loss: 0.714374, Acc: 0.776236\n",
      "Test Loss: 0.723305, Acc: 0.766919\n",
      "Time:7.0 s\n",
      "**********\n",
      "epoch 12\n",
      "[12/100] Loss: 0.704094, Acc: 0.780156\n",
      "[12/100] Loss: 0.703417, Acc: 0.779818\n",
      "[12/100] Loss: 0.701297, Acc: 0.779931\n",
      "Finish 12 epoch, Loss: 0.700639, Acc: 0.780534\n",
      "Test Loss: 0.710623, Acc: 0.770502\n",
      "Time:6.2 s\n",
      "**********\n",
      "epoch 13\n",
      "[13/100] Loss: 0.687044, Acc: 0.787656\n",
      "[13/100] Loss: 0.691940, Acc: 0.783828\n",
      "[13/100] Loss: 0.688653, Acc: 0.784219\n",
      "Finish 13 epoch, Loss: 0.688428, Acc: 0.784215\n",
      "Test Loss: 0.699542, Acc: 0.772193\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 14\n",
      "[14/100] Loss: 0.682307, Acc: 0.785781\n",
      "[14/100] Loss: 0.680681, Acc: 0.785755\n",
      "[14/100] Loss: 0.676878, Acc: 0.787309\n",
      "Finish 14 epoch, Loss: 0.677475, Acc: 0.787014\n",
      "Test Loss: 0.689499, Acc: 0.775577\n",
      "Time:6.5 s\n",
      "**********\n",
      "epoch 15\n",
      "[15/100] Loss: 0.675131, Acc: 0.789375\n",
      "[15/100] Loss: 0.670078, Acc: 0.790703\n",
      "[15/100] Loss: 0.667753, Acc: 0.790295\n",
      "Finish 15 epoch, Loss: 0.667817, Acc: 0.790045\n",
      "Test Loss: 0.680897, Acc: 0.779359\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 16\n",
      "[16/100] Loss: 0.656996, Acc: 0.794948\n",
      "[16/100] Loss: 0.656907, Acc: 0.793307\n",
      "[16/100] Loss: 0.660027, Acc: 0.792431\n",
      "Finish 16 epoch, Loss: 0.658906, Acc: 0.792994\n",
      "Test Loss: 0.672479, Acc: 0.782544\n",
      "Time:6.5 s\n",
      "**********\n",
      "epoch 17\n",
      "[17/100] Loss: 0.658492, Acc: 0.794896\n",
      "[17/100] Loss: 0.651951, Acc: 0.796146\n",
      "[17/100] Loss: 0.651451, Acc: 0.795747\n",
      "Finish 17 epoch, Loss: 0.650733, Acc: 0.795942\n",
      "Test Loss: 0.664819, Acc: 0.784932\n",
      "Time:6.7 s\n",
      "**********\n",
      "epoch 18\n",
      "[18/100] Loss: 0.641402, Acc: 0.798906\n",
      "[18/100] Loss: 0.646751, Acc: 0.796719\n",
      "[18/100] Loss: 0.644743, Acc: 0.797101\n",
      "Finish 18 epoch, Loss: 0.643217, Acc: 0.797258\n",
      "Test Loss: 0.658062, Acc: 0.786027\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 19\n",
      "[19/100] Loss: 0.632132, Acc: 0.798802\n",
      "[19/100] Loss: 0.634370, Acc: 0.800859\n",
      "[19/100] Loss: 0.634818, Acc: 0.800330\n",
      "Finish 19 epoch, Loss: 0.636532, Acc: 0.799407\n",
      "Test Loss: 0.651470, Acc: 0.788714\n",
      "Time:7.9 s\n",
      "**********\n",
      "epoch 20\n",
      "[20/100] Loss: 0.636534, Acc: 0.799896\n",
      "[20/100] Loss: 0.629215, Acc: 0.801276\n",
      "[20/100] Loss: 0.630636, Acc: 0.800694\n",
      "Finish 20 epoch, Loss: 0.629984, Acc: 0.801123\n",
      "Test Loss: 0.645587, Acc: 0.789610\n",
      "Time:6.8 s\n",
      "**********\n",
      "epoch 21\n",
      "[21/100] Loss: 0.622523, Acc: 0.804844\n",
      "[21/100] Loss: 0.624015, Acc: 0.802448\n",
      "[21/100] Loss: 0.623090, Acc: 0.803403\n",
      "Finish 21 epoch, Loss: 0.624115, Acc: 0.802755\n",
      "Test Loss: 0.640334, Acc: 0.790506\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 22\n",
      "[22/100] Loss: 0.617562, Acc: 0.805260\n",
      "[22/100] Loss: 0.617317, Acc: 0.805755\n",
      "[22/100] Loss: 0.617716, Acc: 0.804444\n",
      "Finish 22 epoch, Loss: 0.618379, Acc: 0.803988\n",
      "Test Loss: 0.635115, Acc: 0.792596\n",
      "Time:6.1 s\n",
      "**********\n",
      "epoch 23\n",
      "[23/100] Loss: 0.607562, Acc: 0.806562\n",
      "[23/100] Loss: 0.612964, Acc: 0.805443\n",
      "[23/100] Loss: 0.613623, Acc: 0.805486\n",
      "Finish 23 epoch, Loss: 0.613214, Acc: 0.805720\n",
      "Test Loss: 0.630074, Acc: 0.793292\n",
      "Time:7.6 s\n",
      "**********\n",
      "epoch 24\n",
      "[24/100] Loss: 0.607042, Acc: 0.807448\n",
      "[24/100] Loss: 0.608590, Acc: 0.804922\n",
      "[24/100] Loss: 0.608316, Acc: 0.806597\n",
      "Finish 24 epoch, Loss: 0.608290, Acc: 0.806620\n",
      "Test Loss: 0.625739, Acc: 0.794486\n",
      "Time:6.4 s\n",
      "**********\n",
      "epoch 25\n",
      "[25/100] Loss: 0.598287, Acc: 0.811771\n",
      "[25/100] Loss: 0.603441, Acc: 0.807604\n",
      "[25/100] Loss: 0.604735, Acc: 0.807344\n",
      "Finish 25 epoch, Loss: 0.603717, Acc: 0.807703\n",
      "Test Loss: 0.621455, Acc: 0.795681\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 26\n",
      "[26/100] Loss: 0.601384, Acc: 0.812969\n",
      "[26/100] Loss: 0.600426, Acc: 0.810807\n",
      "[26/100] Loss: 0.598433, Acc: 0.809583\n",
      "Finish 26 epoch, Loss: 0.599433, Acc: 0.809152\n",
      "Test Loss: 0.617499, Acc: 0.796676\n",
      "Time:5.8 s\n",
      "**********\n",
      "epoch 27\n",
      "[27/100] Loss: 0.596912, Acc: 0.809375\n",
      "[27/100] Loss: 0.597398, Acc: 0.808307\n",
      "[27/100] Loss: 0.595803, Acc: 0.809514\n",
      "Finish 27 epoch, Loss: 0.595236, Acc: 0.809918\n",
      "Test Loss: 0.613427, Acc: 0.798766\n",
      "Time:6.4 s\n",
      "**********\n",
      "epoch 28\n",
      "[28/100] Loss: 0.587281, Acc: 0.811823\n",
      "[28/100] Loss: 0.592513, Acc: 0.810547\n",
      "[28/100] Loss: 0.591111, Acc: 0.811597\n",
      "Finish 28 epoch, Loss: 0.591429, Acc: 0.811334\n",
      "Test Loss: 0.610171, Acc: 0.800756\n",
      "Time:7.3 s\n",
      "**********\n",
      "epoch 29\n",
      "[29/100] Loss: 0.584121, Acc: 0.811823\n",
      "[29/100] Loss: 0.588348, Acc: 0.810938\n",
      "[29/100] Loss: 0.586831, Acc: 0.812552\n",
      "Finish 29 epoch, Loss: 0.587645, Acc: 0.812567\n",
      "Test Loss: 0.606339, Acc: 0.801055\n",
      "Time:9.2 s\n",
      "**********\n",
      "epoch 30\n",
      "[30/100] Loss: 0.586091, Acc: 0.811979\n",
      "[30/100] Loss: 0.585771, Acc: 0.811693\n",
      "[30/100] Loss: 0.585332, Acc: 0.812726\n",
      "Finish 30 epoch, Loss: 0.583996, Acc: 0.813166\n",
      "Test Loss: 0.603177, Acc: 0.802448\n",
      "Time:8.7 s\n",
      "**********\n",
      "epoch 31\n",
      "[31/100] Loss: 0.585025, Acc: 0.811406\n",
      "[31/100] Loss: 0.579258, Acc: 0.814740\n",
      "[31/100] Loss: 0.581116, Acc: 0.813733\n",
      "Finish 31 epoch, Loss: 0.580601, Acc: 0.814132\n",
      "Test Loss: 0.600076, Acc: 0.801652\n",
      "Time:8.6 s\n",
      "**********\n",
      "epoch 32\n",
      "[32/100] Loss: 0.578489, Acc: 0.815677\n",
      "[32/100] Loss: 0.579338, Acc: 0.814297\n",
      "[32/100] Loss: 0.576931, Acc: 0.815278\n",
      "Finish 32 epoch, Loss: 0.577460, Acc: 0.814832\n",
      "Test Loss: 0.597132, Acc: 0.804140\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 33\n",
      "[33/100] Loss: 0.576335, Acc: 0.815417\n",
      "[33/100] Loss: 0.576760, Acc: 0.815417\n",
      "[33/100] Loss: 0.575286, Acc: 0.815903\n",
      "Finish 33 epoch, Loss: 0.574363, Acc: 0.816031\n",
      "Test Loss: 0.594010, Acc: 0.804936\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 34\n",
      "[34/100] Loss: 0.576290, Acc: 0.813125\n",
      "[34/100] Loss: 0.573333, Acc: 0.815182\n",
      "[34/100] Loss: 0.571385, Acc: 0.816771\n",
      "Finish 34 epoch, Loss: 0.571389, Acc: 0.816648\n",
      "Test Loss: 0.591275, Acc: 0.805633\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 35\n",
      "[35/100] Loss: 0.570389, Acc: 0.818698\n",
      "[35/100] Loss: 0.566902, Acc: 0.818021\n",
      "[35/100] Loss: 0.569117, Acc: 0.816944\n",
      "Finish 35 epoch, Loss: 0.568623, Acc: 0.816881\n",
      "Test Loss: 0.588818, Acc: 0.806031\n",
      "Time:6.7 s\n",
      "**********\n",
      "epoch 36\n",
      "[36/100] Loss: 0.562697, Acc: 0.818958\n",
      "[36/100] Loss: 0.566940, Acc: 0.817057\n",
      "[36/100] Loss: 0.565453, Acc: 0.817917\n",
      "Finish 36 epoch, Loss: 0.565944, Acc: 0.817864\n",
      "Test Loss: 0.586217, Acc: 0.807424\n",
      "Time:6.5 s\n",
      "**********\n",
      "epoch 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/100] Loss: 0.561875, Acc: 0.820156\n",
      "[37/100] Loss: 0.564733, Acc: 0.818359\n",
      "[37/100] Loss: 0.562611, Acc: 0.818767\n",
      "Finish 37 epoch, Loss: 0.563145, Acc: 0.818663\n",
      "Test Loss: 0.584233, Acc: 0.807026\n",
      "Time:6.6 s\n",
      "**********\n",
      "epoch 38\n",
      "[38/100] Loss: 0.562870, Acc: 0.819427\n",
      "[38/100] Loss: 0.564367, Acc: 0.818333\n",
      "[38/100] Loss: 0.561862, Acc: 0.818906\n",
      "Finish 38 epoch, Loss: 0.560687, Acc: 0.819430\n",
      "Test Loss: 0.581504, Acc: 0.807822\n",
      "Time:7.0 s\n",
      "**********\n",
      "epoch 39\n",
      "[39/100] Loss: 0.550216, Acc: 0.823958\n",
      "[39/100] Loss: 0.557122, Acc: 0.821328\n",
      "[39/100] Loss: 0.558182, Acc: 0.820347\n",
      "Finish 39 epoch, Loss: 0.558331, Acc: 0.820079\n",
      "Test Loss: 0.579366, Acc: 0.809116\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 40\n",
      "[40/100] Loss: 0.563126, Acc: 0.822031\n",
      "[40/100] Loss: 0.557163, Acc: 0.821406\n",
      "[40/100] Loss: 0.555319, Acc: 0.820885\n",
      "Finish 40 epoch, Loss: 0.555976, Acc: 0.820729\n",
      "Test Loss: 0.577216, Acc: 0.808718\n",
      "Time:7.4 s\n",
      "**********\n",
      "epoch 41\n",
      "[41/100] Loss: 0.554774, Acc: 0.822760\n",
      "[41/100] Loss: 0.553468, Acc: 0.821953\n",
      "[41/100] Loss: 0.553363, Acc: 0.821632\n",
      "Finish 41 epoch, Loss: 0.553722, Acc: 0.821695\n",
      "Test Loss: 0.575129, Acc: 0.809614\n",
      "Time:6.9 s\n",
      "**********\n",
      "epoch 42\n",
      "[42/100] Loss: 0.548504, Acc: 0.823073\n",
      "[42/100] Loss: 0.552149, Acc: 0.821354\n",
      "[42/100] Loss: 0.550956, Acc: 0.821684\n",
      "Finish 42 epoch, Loss: 0.551522, Acc: 0.821762\n",
      "Test Loss: 0.573040, Acc: 0.810211\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 43\n",
      "[43/100] Loss: 0.549031, Acc: 0.824740\n",
      "[43/100] Loss: 0.551578, Acc: 0.823568\n",
      "[43/100] Loss: 0.550031, Acc: 0.822517\n",
      "Finish 43 epoch, Loss: 0.549542, Acc: 0.822628\n",
      "Test Loss: 0.571325, Acc: 0.810111\n",
      "Time:6.8 s\n",
      "**********\n",
      "epoch 44\n",
      "[44/100] Loss: 0.546671, Acc: 0.824635\n",
      "[44/100] Loss: 0.549286, Acc: 0.821693\n",
      "[44/100] Loss: 0.546555, Acc: 0.822899\n",
      "Finish 44 epoch, Loss: 0.547430, Acc: 0.822395\n",
      "Test Loss: 0.569373, Acc: 0.811405\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 45\n",
      "[45/100] Loss: 0.548058, Acc: 0.825365\n",
      "[45/100] Loss: 0.545825, Acc: 0.824141\n",
      "[45/100] Loss: 0.545769, Acc: 0.823194\n",
      "Finish 45 epoch, Loss: 0.545695, Acc: 0.823611\n",
      "Test Loss: 0.567551, Acc: 0.811604\n",
      "Time:7.3 s\n",
      "**********\n",
      "epoch 46\n",
      "[46/100] Loss: 0.542882, Acc: 0.823646\n",
      "[46/100] Loss: 0.544659, Acc: 0.822682\n",
      "[46/100] Loss: 0.542407, Acc: 0.824392\n",
      "Finish 46 epoch, Loss: 0.543521, Acc: 0.823711\n",
      "Test Loss: 0.565740, Acc: 0.812201\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 47\n",
      "[47/100] Loss: 0.537232, Acc: 0.827865\n",
      "[47/100] Loss: 0.540230, Acc: 0.826276\n",
      "[47/100] Loss: 0.541849, Acc: 0.824913\n",
      "Finish 47 epoch, Loss: 0.541724, Acc: 0.824860\n",
      "Test Loss: 0.564083, Acc: 0.812301\n",
      "Time:6.2 s\n",
      "**********\n",
      "epoch 48\n",
      "[48/100] Loss: 0.537468, Acc: 0.824219\n",
      "[48/100] Loss: 0.543873, Acc: 0.823021\n",
      "[48/100] Loss: 0.539419, Acc: 0.825174\n",
      "Finish 48 epoch, Loss: 0.539966, Acc: 0.825243\n",
      "Test Loss: 0.562542, Acc: 0.812400\n",
      "Time:7.3 s\n",
      "**********\n",
      "epoch 49\n",
      "[49/100] Loss: 0.541973, Acc: 0.823438\n",
      "[49/100] Loss: 0.542127, Acc: 0.823438\n",
      "[49/100] Loss: 0.538940, Acc: 0.825295\n",
      "Finish 49 epoch, Loss: 0.538093, Acc: 0.825476\n",
      "Test Loss: 0.560732, Acc: 0.813396\n",
      "Time:6.9 s\n",
      "**********\n",
      "epoch 50\n",
      "[50/100] Loss: 0.535747, Acc: 0.824583\n",
      "[50/100] Loss: 0.536108, Acc: 0.825911\n",
      "[50/100] Loss: 0.536705, Acc: 0.825833\n",
      "Finish 50 epoch, Loss: 0.536453, Acc: 0.825776\n",
      "Test Loss: 0.559200, Acc: 0.813197\n",
      "Time:6.4 s\n",
      "**********\n",
      "epoch 51\n",
      "[51/100] Loss: 0.528348, Acc: 0.830417\n",
      "[51/100] Loss: 0.534660, Acc: 0.827630\n",
      "[51/100] Loss: 0.535018, Acc: 0.826406\n",
      "Finish 51 epoch, Loss: 0.534796, Acc: 0.826259\n",
      "Test Loss: 0.557706, Acc: 0.813396\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 52\n",
      "[52/100] Loss: 0.538038, Acc: 0.823542\n",
      "[52/100] Loss: 0.537634, Acc: 0.825573\n",
      "[52/100] Loss: 0.534611, Acc: 0.825816\n",
      "Finish 52 epoch, Loss: 0.533190, Acc: 0.826576\n",
      "Test Loss: 0.556503, Acc: 0.814192\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 53\n",
      "[53/100] Loss: 0.534169, Acc: 0.825625\n",
      "[53/100] Loss: 0.531194, Acc: 0.826797\n",
      "[53/100] Loss: 0.531648, Acc: 0.827118\n",
      "Finish 53 epoch, Loss: 0.531635, Acc: 0.827126\n",
      "Test Loss: 0.554973, Acc: 0.814490\n",
      "Time:7.0 s\n",
      "**********\n",
      "epoch 54\n",
      "[54/100] Loss: 0.528328, Acc: 0.827969\n",
      "[54/100] Loss: 0.530838, Acc: 0.827266\n",
      "[54/100] Loss: 0.530653, Acc: 0.826788\n",
      "Finish 54 epoch, Loss: 0.530202, Acc: 0.827325\n",
      "Test Loss: 0.553434, Acc: 0.814690\n",
      "Time:6.2 s\n",
      "**********\n",
      "epoch 55\n",
      "[55/100] Loss: 0.520252, Acc: 0.830625\n",
      "[55/100] Loss: 0.527814, Acc: 0.828620\n",
      "[55/100] Loss: 0.527535, Acc: 0.828003\n",
      "Finish 55 epoch, Loss: 0.528667, Acc: 0.827609\n",
      "Test Loss: 0.552304, Acc: 0.815287\n",
      "Time:6.1 s\n",
      "**********\n",
      "epoch 56\n",
      "[56/100] Loss: 0.521816, Acc: 0.831146\n",
      "[56/100] Loss: 0.526438, Acc: 0.828359\n",
      "[56/100] Loss: 0.527653, Acc: 0.827674\n",
      "Finish 56 epoch, Loss: 0.527245, Acc: 0.827908\n",
      "Test Loss: 0.550941, Acc: 0.815287\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 57\n",
      "[57/100] Loss: 0.530969, Acc: 0.827083\n",
      "[57/100] Loss: 0.524694, Acc: 0.829271\n",
      "[57/100] Loss: 0.525950, Acc: 0.828785\n",
      "Finish 57 epoch, Loss: 0.525805, Acc: 0.828708\n",
      "Test Loss: 0.549741, Acc: 0.816381\n",
      "Time:6.6 s\n",
      "**********\n",
      "epoch 58\n",
      "[58/100] Loss: 0.522215, Acc: 0.830104\n",
      "[58/100] Loss: 0.524514, Acc: 0.828906\n",
      "[58/100] Loss: 0.524261, Acc: 0.828785\n",
      "Finish 58 epoch, Loss: 0.524502, Acc: 0.828808\n",
      "Test Loss: 0.548330, Acc: 0.815983\n",
      "Time:6.1 s\n",
      "**********\n",
      "epoch 59\n",
      "[59/100] Loss: 0.519355, Acc: 0.830885\n",
      "[59/100] Loss: 0.522470, Acc: 0.829167\n",
      "[59/100] Loss: 0.523618, Acc: 0.828906\n",
      "Finish 59 epoch, Loss: 0.523245, Acc: 0.828775\n",
      "Test Loss: 0.547063, Acc: 0.816282\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 60\n",
      "[60/100] Loss: 0.524286, Acc: 0.826042\n",
      "[60/100] Loss: 0.521801, Acc: 0.828672\n",
      "[60/100] Loss: 0.521943, Acc: 0.828889\n",
      "Finish 60 epoch, Loss: 0.521943, Acc: 0.828925\n",
      "Test Loss: 0.545998, Acc: 0.816879\n",
      "Time:5.8 s\n",
      "**********\n",
      "epoch 61\n",
      "[61/100] Loss: 0.518765, Acc: 0.830833\n",
      "[61/100] Loss: 0.518556, Acc: 0.830807\n",
      "[61/100] Loss: 0.520953, Acc: 0.829740\n",
      "Finish 61 epoch, Loss: 0.520659, Acc: 0.829757\n",
      "Test Loss: 0.544823, Acc: 0.817377\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 62\n",
      "[62/100] Loss: 0.521368, Acc: 0.830000\n",
      "[62/100] Loss: 0.521712, Acc: 0.829219\n",
      "[62/100] Loss: 0.519629, Acc: 0.829687\n",
      "Finish 62 epoch, Loss: 0.519348, Acc: 0.829857\n",
      "Test Loss: 0.543646, Acc: 0.817277\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 63\n",
      "[63/100] Loss: 0.513272, Acc: 0.831146\n",
      "[63/100] Loss: 0.517980, Acc: 0.830651\n",
      "[63/100] Loss: 0.517530, Acc: 0.830469\n",
      "Finish 63 epoch, Loss: 0.518064, Acc: 0.830374\n",
      "Test Loss: 0.542926, Acc: 0.818173\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 64\n",
      "[64/100] Loss: 0.521259, Acc: 0.829427\n",
      "[64/100] Loss: 0.517371, Acc: 0.829479\n",
      "[64/100] Loss: 0.518472, Acc: 0.829913\n",
      "Finish 64 epoch, Loss: 0.517012, Acc: 0.830091\n",
      "Test Loss: 0.541702, Acc: 0.818372\n",
      "Time:5.8 s\n",
      "**********\n",
      "epoch 65\n",
      "[65/100] Loss: 0.508709, Acc: 0.836979\n",
      "[65/100] Loss: 0.514733, Acc: 0.831641\n",
      "[65/100] Loss: 0.516538, Acc: 0.830434\n",
      "Finish 65 epoch, Loss: 0.515806, Acc: 0.830574\n",
      "Test Loss: 0.540531, Acc: 0.818869\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 66\n",
      "[66/100] Loss: 0.515416, Acc: 0.829740\n",
      "[66/100] Loss: 0.515687, Acc: 0.830234\n",
      "[66/100] Loss: 0.514227, Acc: 0.831111\n",
      "Finish 66 epoch, Loss: 0.514719, Acc: 0.830907\n",
      "Test Loss: 0.539427, Acc: 0.818670\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 67\n",
      "[67/100] Loss: 0.513200, Acc: 0.833490\n",
      "[67/100] Loss: 0.511978, Acc: 0.833594\n",
      "[67/100] Loss: 0.512875, Acc: 0.831389\n",
      "Finish 67 epoch, Loss: 0.513596, Acc: 0.831140\n",
      "Test Loss: 0.538392, Acc: 0.819467\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 68\n",
      "[68/100] Loss: 0.521818, Acc: 0.828542\n",
      "[68/100] Loss: 0.516457, Acc: 0.829271\n",
      "[68/100] Loss: 0.513279, Acc: 0.831198\n",
      "Finish 68 epoch, Loss: 0.512603, Acc: 0.831323\n",
      "Test Loss: 0.537355, Acc: 0.819068\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 69\n",
      "[69/100] Loss: 0.515646, Acc: 0.825677\n",
      "[69/100] Loss: 0.514802, Acc: 0.828802\n",
      "[69/100] Loss: 0.511558, Acc: 0.830851\n",
      "Finish 69 epoch, Loss: 0.511389, Acc: 0.831390\n",
      "Test Loss: 0.536417, Acc: 0.819168\n",
      "Time:5.7 s\n",
      "**********\n",
      "epoch 70\n",
      "[70/100] Loss: 0.501545, Acc: 0.836354\n",
      "[70/100] Loss: 0.506520, Acc: 0.834974\n",
      "[70/100] Loss: 0.510325, Acc: 0.832205\n",
      "Finish 70 epoch, Loss: 0.510342, Acc: 0.831956\n",
      "Test Loss: 0.535620, Acc: 0.820163\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 71\n",
      "[71/100] Loss: 0.505172, Acc: 0.833438\n",
      "[71/100] Loss: 0.505446, Acc: 0.834297\n",
      "[71/100] Loss: 0.508152, Acc: 0.832795\n",
      "Finish 71 epoch, Loss: 0.509356, Acc: 0.832223\n",
      "Test Loss: 0.534603, Acc: 0.819964\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 72\n",
      "[72/100] Loss: 0.507012, Acc: 0.831458\n",
      "[72/100] Loss: 0.510562, Acc: 0.831875\n",
      "[72/100] Loss: 0.509394, Acc: 0.832066\n",
      "Finish 72 epoch, Loss: 0.508390, Acc: 0.832389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.533706, Acc: 0.819765\n",
      "Time:6.9 s\n",
      "**********\n",
      "epoch 73\n",
      "[73/100] Loss: 0.503612, Acc: 0.833646\n",
      "[73/100] Loss: 0.503940, Acc: 0.834427\n",
      "[73/100] Loss: 0.505940, Acc: 0.833542\n",
      "Finish 73 epoch, Loss: 0.507404, Acc: 0.832989\n",
      "Test Loss: 0.532815, Acc: 0.820561\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 74\n",
      "[74/100] Loss: 0.509078, Acc: 0.831094\n",
      "[74/100] Loss: 0.510290, Acc: 0.831042\n",
      "[74/100] Loss: 0.507139, Acc: 0.832396\n",
      "Finish 74 epoch, Loss: 0.506471, Acc: 0.832839\n",
      "Test Loss: 0.531957, Acc: 0.820860\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 75\n",
      "[75/100] Loss: 0.508001, Acc: 0.830417\n",
      "[75/100] Loss: 0.504039, Acc: 0.834583\n",
      "[75/100] Loss: 0.505196, Acc: 0.833472\n",
      "Finish 75 epoch, Loss: 0.505445, Acc: 0.833239\n",
      "Test Loss: 0.531179, Acc: 0.821059\n",
      "Time:6.1 s\n",
      "**********\n",
      "epoch 76\n",
      "[76/100] Loss: 0.502922, Acc: 0.835625\n",
      "[76/100] Loss: 0.503750, Acc: 0.833307\n",
      "[76/100] Loss: 0.504543, Acc: 0.832951\n",
      "Finish 76 epoch, Loss: 0.504508, Acc: 0.833306\n",
      "Test Loss: 0.530319, Acc: 0.820959\n",
      "Time:5.8 s\n",
      "**********\n",
      "epoch 77\n",
      "[77/100] Loss: 0.500669, Acc: 0.833906\n",
      "[77/100] Loss: 0.504114, Acc: 0.832682\n",
      "[77/100] Loss: 0.503270, Acc: 0.833438\n",
      "Finish 77 epoch, Loss: 0.503766, Acc: 0.833472\n",
      "Test Loss: 0.529525, Acc: 0.821357\n",
      "Time:7.4 s\n",
      "**********\n",
      "epoch 78\n",
      "[78/100] Loss: 0.497965, Acc: 0.837812\n",
      "[78/100] Loss: 0.504625, Acc: 0.833594\n",
      "[78/100] Loss: 0.503768, Acc: 0.833281\n",
      "Finish 78 epoch, Loss: 0.502642, Acc: 0.833755\n",
      "Test Loss: 0.528649, Acc: 0.821756\n",
      "Time:7.3 s\n",
      "**********\n",
      "epoch 79\n",
      "[79/100] Loss: 0.505444, Acc: 0.833542\n",
      "[79/100] Loss: 0.501078, Acc: 0.834922\n",
      "[79/100] Loss: 0.501936, Acc: 0.833698\n",
      "Finish 79 epoch, Loss: 0.501786, Acc: 0.833772\n",
      "Test Loss: 0.528088, Acc: 0.822651\n",
      "Time:6.3 s\n",
      "**********\n",
      "epoch 80\n",
      "[80/100] Loss: 0.488993, Acc: 0.841510\n",
      "[80/100] Loss: 0.494842, Acc: 0.837396\n",
      "[80/100] Loss: 0.500413, Acc: 0.834653\n",
      "Finish 80 epoch, Loss: 0.500995, Acc: 0.834738\n",
      "Test Loss: 0.527044, Acc: 0.821855\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 81\n",
      "[81/100] Loss: 0.501951, Acc: 0.836875\n",
      "[81/100] Loss: 0.500569, Acc: 0.835130\n",
      "[81/100] Loss: 0.500058, Acc: 0.834670\n",
      "Finish 81 epoch, Loss: 0.500304, Acc: 0.834488\n",
      "Test Loss: 0.526278, Acc: 0.821855\n",
      "Time:5.7 s\n",
      "**********\n",
      "epoch 82\n",
      "[82/100] Loss: 0.500545, Acc: 0.834740\n",
      "[82/100] Loss: 0.498367, Acc: 0.834271\n",
      "[82/100] Loss: 0.499010, Acc: 0.834931\n",
      "Finish 82 epoch, Loss: 0.499304, Acc: 0.834771\n",
      "Test Loss: 0.525559, Acc: 0.823149\n",
      "Time:7.9 s\n",
      "**********\n",
      "epoch 83\n",
      "[83/100] Loss: 0.503597, Acc: 0.833906\n",
      "[83/100] Loss: 0.499209, Acc: 0.834948\n",
      "[83/100] Loss: 0.498550, Acc: 0.834444\n",
      "Finish 83 epoch, Loss: 0.498569, Acc: 0.834855\n",
      "Test Loss: 0.524868, Acc: 0.822452\n",
      "Time:7.9 s\n",
      "**********\n",
      "epoch 84\n",
      "[84/100] Loss: 0.497355, Acc: 0.835052\n",
      "[84/100] Loss: 0.496171, Acc: 0.836328\n",
      "[84/100] Loss: 0.497103, Acc: 0.835503\n",
      "Finish 84 epoch, Loss: 0.497799, Acc: 0.835321\n",
      "Test Loss: 0.524106, Acc: 0.822452\n",
      "Time:8.6 s\n",
      "**********\n",
      "epoch 85\n",
      "[85/100] Loss: 0.498440, Acc: 0.836302\n",
      "[85/100] Loss: 0.498912, Acc: 0.835339\n",
      "[85/100] Loss: 0.497618, Acc: 0.835677\n",
      "Finish 85 epoch, Loss: 0.496861, Acc: 0.835721\n",
      "Test Loss: 0.523657, Acc: 0.824244\n",
      "Time:6.9 s\n",
      "**********\n",
      "epoch 86\n",
      "[86/100] Loss: 0.494272, Acc: 0.835521\n",
      "[86/100] Loss: 0.496718, Acc: 0.834557\n",
      "[86/100] Loss: 0.495814, Acc: 0.835399\n",
      "Finish 86 epoch, Loss: 0.496214, Acc: 0.835388\n",
      "Test Loss: 0.522744, Acc: 0.823447\n",
      "Time:7.2 s\n",
      "**********\n",
      "epoch 87\n",
      "[87/100] Loss: 0.492002, Acc: 0.838750\n",
      "[87/100] Loss: 0.498921, Acc: 0.834844\n",
      "[87/100] Loss: 0.496407, Acc: 0.835330\n",
      "Finish 87 epoch, Loss: 0.495388, Acc: 0.835821\n",
      "Test Loss: 0.522133, Acc: 0.823447\n",
      "Time:7.5 s\n",
      "**********\n",
      "epoch 88\n",
      "[88/100] Loss: 0.493595, Acc: 0.836146\n",
      "[88/100] Loss: 0.492838, Acc: 0.836745\n",
      "[88/100] Loss: 0.494837, Acc: 0.836181\n",
      "Finish 88 epoch, Loss: 0.494832, Acc: 0.836087\n",
      "Test Loss: 0.521498, Acc: 0.823547\n",
      "Time:6.2 s\n",
      "**********\n",
      "epoch 89\n",
      "[89/100] Loss: 0.495263, Acc: 0.835885\n",
      "[89/100] Loss: 0.494564, Acc: 0.835443\n",
      "[89/100] Loss: 0.494408, Acc: 0.836302\n",
      "Finish 89 epoch, Loss: 0.493951, Acc: 0.836354\n",
      "Test Loss: 0.520984, Acc: 0.823149\n",
      "Time:6.5 s\n",
      "**********\n",
      "epoch 90\n",
      "[90/100] Loss: 0.498815, Acc: 0.833385\n",
      "[90/100] Loss: 0.497034, Acc: 0.834557\n",
      "[90/100] Loss: 0.493278, Acc: 0.836076\n",
      "Finish 90 epoch, Loss: 0.493293, Acc: 0.836404\n",
      "Test Loss: 0.520192, Acc: 0.824045\n",
      "Time:6.1 s\n",
      "**********\n",
      "epoch 91\n",
      "[91/100] Loss: 0.492191, Acc: 0.836615\n",
      "[91/100] Loss: 0.494900, Acc: 0.836172\n",
      "[91/100] Loss: 0.492225, Acc: 0.836944\n",
      "Finish 91 epoch, Loss: 0.492576, Acc: 0.836654\n",
      "Test Loss: 0.519433, Acc: 0.824443\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 92\n",
      "[92/100] Loss: 0.488954, Acc: 0.833594\n",
      "[92/100] Loss: 0.494269, Acc: 0.834583\n",
      "[92/100] Loss: 0.491809, Acc: 0.836285\n",
      "Finish 92 epoch, Loss: 0.491800, Acc: 0.836404\n",
      "Test Loss: 0.518823, Acc: 0.824045\n",
      "Time:6.0 s\n",
      "**********\n",
      "epoch 93\n",
      "[93/100] Loss: 0.490434, Acc: 0.836198\n",
      "[93/100] Loss: 0.489947, Acc: 0.837526\n",
      "[93/100] Loss: 0.490111, Acc: 0.837240\n",
      "Finish 93 epoch, Loss: 0.491276, Acc: 0.837120\n",
      "Test Loss: 0.518162, Acc: 0.824542\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 94\n",
      "[94/100] Loss: 0.481345, Acc: 0.841094\n",
      "[94/100] Loss: 0.482986, Acc: 0.839297\n",
      "[94/100] Loss: 0.489491, Acc: 0.837118\n",
      "Finish 94 epoch, Loss: 0.490527, Acc: 0.836870\n",
      "Test Loss: 0.517570, Acc: 0.824841\n",
      "Time:5.8 s\n",
      "**********\n",
      "epoch 95\n",
      "[95/100] Loss: 0.490438, Acc: 0.836458\n",
      "[95/100] Loss: 0.492323, Acc: 0.836120\n",
      "[95/100] Loss: 0.490322, Acc: 0.837517\n",
      "Finish 95 epoch, Loss: 0.489810, Acc: 0.837453\n",
      "Test Loss: 0.516985, Acc: 0.825139\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 96\n",
      "[96/100] Loss: 0.495225, Acc: 0.832031\n",
      "[96/100] Loss: 0.490825, Acc: 0.836719\n",
      "[96/100] Loss: 0.488747, Acc: 0.837899\n",
      "Finish 96 epoch, Loss: 0.489082, Acc: 0.837487\n",
      "Test Loss: 0.516443, Acc: 0.825040\n",
      "Time:5.8 s\n",
      "**********\n",
      "epoch 97\n",
      "[97/100] Loss: 0.487549, Acc: 0.838594\n",
      "[97/100] Loss: 0.489600, Acc: 0.837630\n",
      "[97/100] Loss: 0.488897, Acc: 0.837031\n",
      "Finish 97 epoch, Loss: 0.488413, Acc: 0.837220\n",
      "Test Loss: 0.516111, Acc: 0.825537\n",
      "Time:5.9 s\n",
      "**********\n",
      "epoch 98\n",
      "[98/100] Loss: 0.496258, Acc: 0.834635\n",
      "[98/100] Loss: 0.489404, Acc: 0.836641\n",
      "[98/100] Loss: 0.488109, Acc: 0.837222\n",
      "Finish 98 epoch, Loss: 0.487843, Acc: 0.837303\n",
      "Test Loss: 0.515266, Acc: 0.826334\n",
      "Time:6.5 s\n",
      "**********\n",
      "epoch 99\n",
      "[99/100] Loss: 0.481252, Acc: 0.840365\n",
      "[99/100] Loss: 0.485293, Acc: 0.837578\n",
      "[99/100] Loss: 0.486452, Acc: 0.837899\n",
      "Finish 99 epoch, Loss: 0.487162, Acc: 0.837770\n",
      "Test Loss: 0.514663, Acc: 0.826632\n",
      "Time:7.1 s\n",
      "**********\n",
      "epoch 100\n",
      "[100/100] Loss: 0.486523, Acc: 0.838385\n",
      "[100/100] Loss: 0.485665, Acc: 0.838516\n",
      "[100/100] Loss: 0.487212, Acc: 0.837691\n",
      "Finish 100 epoch, Loss: 0.486553, Acc: 0.837803\n",
      "Test Loss: 0.514230, Acc: 0.825935\n",
      "Time:7.6 s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print('*' * 10)\n",
    "    print(f'epoch {epoch+1}')\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1) \n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item()\n",
    "        _, pred = torch.max(out, 1)\n",
    "        running_acc += (pred==label).float().mean()\n",
    "       # zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print(f'[{epoch+1}/{num_epochs}] Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}')\n",
    "    print(f'Finish {epoch+1} epoch, Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}')\n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        with torch.no_grad():\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "        eval_loss += loss.item()\n",
    "        _, pred = torch.max(out, 1)\n",
    "        eval_acc += (pred == label).float().mean()\n",
    "    print(f'Test Loss: {eval_loss/len(test_loader):.6f}, Acc: {eval_acc/len(test_loader):.6f}')\n",
    "    print(f'Time:{(time.time()-since):.1f} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './logstic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
